[{"title":"HashTable、HashMap和ConCurrentHashMap区别","date":"2018-04-04T08:19:04.000Z","path":"2018/04/04/HashTable、HashMap和ConCurrentHashMap区别/","text":"HashMap和HashTable的对比 1.HashMap是非线程安全的，HashTable是线程安全的。 Hashtable中的线程安全是Synchronize的（sychronized意味着在一次仅有一个线程能够更改Hashtable，就是说任何线程要更新Hashtable时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新Hashtable）；而HashMap中的方法在缺省情况下是非Synchronize的。所以在单线程环境下Hashtable比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。 在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用HashMap时就必须要自己增加同步处理： Map m =Collections.synchronizedMap(new HashMap(…))。 2.HashMap的键和值都允许有null存在，而HashTable则都不行。 3.因为线程安全、哈希效率的问题，HashMap效率比HashTable的要高。 4.哈希值的使用不同 HashTable直接使用对象的hashCode。而HashMap重新计算hash值。 5.内部实现使用的数组初始化和扩容方式不同 HashMap默认初始化数组的大小为16，要求底层数组的容量一定要为2的整数次幂，HashTable为11。HashMap扩容时乘2，使用位运算取得哈希，效率高于取模。而HashTable为乘2加1，都是素数和奇数，这样取模哈希结果更均匀。 6.继承的父类不同 Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类。但二者都实现了Map接口。 7.两个遍历方式的内部实现上不同 Hashtable、HashMap都使用了 Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式。 8.是否提供contains方法 HashMap把Hashtable的contains方法去掉了，改成containsValue和containsKey，因为contains方法容易让人引起误解。 Hashtable则保留了contains，containsValue和containsKey三个方法，其中contains和containsValue功能相同。 HashTable和ConCurrentHashMap的对比ConcurrentHashMap引入了分割(Segment)，上面代码中的最后一行其实就可以理解为把一个大的Map拆分成N个小的HashTable，在put方法中，会根据hash(paramK.hashCode())来决定具体存放进哪个Segment，如果查看Segment的put操作，我们会发现内部使用的同步机制是基于lock操作的，这样就可以对Map的一部分（Segment）进行上锁，这样影响的只是将要放入同一个Segment的元素的put操作，保证同步的时候，锁住的不是整个Map（HashTable就是这么做的），相对于HashTable提高了多线程环境下的性能，因此HashTable已经被淘汰了。 HashMap和ConCurrentHashMap的对比（1）ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的syn关键字锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。 （2）HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"排序算法","date":"2018-04-03T13:18:20.000Z","path":"2018/04/03/排序算法/","text":"综述内排序有可以分为以下几类： (1)、插入排序：直接插入排序、二分法插入排序、希尔排序。(2)、选择排序：简单选择排序、堆排序。(3)、交换排序：冒泡排序、快速排序。(4)、归并排序(5)、基数排序 排序方法 平均情况 最好情况 最坏情况 空间复杂度 稳定性 插入排序 O(n2) O(n) O(n2) O(1) 稳定 shell排序 O(n1.3) O(n) O(n2) O(1) 不稳定 选择排序 O(n2) O(n2) O(n2) O(1) 不稳定 堆排序 O(nlog2n) O(nlog2n) O(nlog2n) O(1) 不稳定 冒泡排序 O(n2) O(n) O(n2) O(1) 稳定 快速排序 O(nlog2n) O(nlog2n) O(n2) O(nlog2n) 不稳定 归并排序 O(nlog2n) O(nlog2n) O(nlog2n) O(1) 稳定 基数排序 O(d(r+n)) O(d(r+rd)) O(d(r+n)) O(rd+n) 稳定 注：基数排序 r表示关键字的基数 d代表长度 n代表关键字的个数 - O（n2）排序冒泡排序基本思想：比较数组相邻的两个值，把大的像泡泡一样“冒”到数组后面去，一共要执行N的平方除以2这么多次的比较和交换的操作（N为数组元素），其复杂度为Ο(n²)。 1234567891011public static void bubbleSort(int[] arr)&#123; for(int i=0;i&lt;arr.length-1;i++)&#123;//外层循环控制排序趟数 for(int j=0;j&lt;arr.length-1-i;j++)&#123;//内层循环控制每一趟排序多少次 if(arr[j]&gt;arr[j+1])&#123; int temp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=temp; &#125; &#125; &#125;&#125; 选择排序123456789101112131415161718public static void selectsort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; for(int i=0;i&lt;arr.length;i++)&#123; int index = i;//初始下标为i for(int j=i+1;j&lt;arr.length;j++)&#123; if(arr[j]&lt;arr[index])&#123; index = j; &#125; &#125; if(index != i)&#123; int temp = arr[index]; arr[index] = arr[i]; arr[i] = temp; &#125; &#125;&#125; 插入排序基本思想：每步将一个待排序的记录，按其顺序码大小插入到前面已经排序的字序列的合适位置（从后向前找到合适位置后），直到全部插入排序完为止。 1234567891011public static void insertSort(int[] a) &#123; for(int i = 1; i &lt; a.length; i++) &#123;// 从数组的第二个元素开始循环将数组中的元素插入 int temp = a[i];// 设置数组中的第2个元素为第一次循环要插入的数据 int j = i - 1; while (j &gt;= 0 &amp;&amp; temp &lt; a[j]) &#123; a[j + 1] = a[j];// 如果要插入的元素小于第j个元素,就将第j个元素向后移动 j--; &#125; a[j + 1] = temp;// 直到要插入的元素不小于第j个元素,将temp插入到数组中 &#125;&#125; shell排序基本思想：本质是插入排序，通过将数组数组的方式来将增加排序的速度，分组的方式第一次将数组的长度/2,第二次/4,当结果等于1的时候，那么将这个数组进行插入排序就完成了排序，当然分组时也是需要排序的。 123456789101112131415public static void shellSort(int[] a) &#123; // 将数组分组 for (int temp = a.length / 2; temp &gt;= 1; temp /= 2) &#123; // 这里的思路和插入排序的思路相同，通过找到前一个的数大于或者小于来进行插入 for(int i = temp; i &lt; a.length; i += temp) &#123; int temp = a[i]; int j = i - temp; while(j &gt;= 0 &amp;&amp; temp &lt; a[j]) &#123; a[j + temp] = a[j]; j -= temp; &#125; a[j + temp] = temp; &#125; &#125; &#125; O（nlog2n）排序快速排序12345678910111213141516171819public static void quickSort(int[] arr,int low,int high)&#123; if(low &gt; high)&#123; return ; &#125; int i = low, j = high,temp = arr[low]; while(i &lt; j)&#123; while( arr[j] &gt;= temp &amp;&amp; i &lt; j)&#123; j--; &#125; arr[i] = arr[j]; while(arr[i] &lt;= temp &amp;&amp; i &lt; j)&#123; i++; &#125; arr[j] = arr[i]; &#125; arr[j] = temp; quickSort(arr,low,j-1); quickSort(arr,j+1,high);&#125; 归并排序（1）稳定性：归并排序是一种稳定的排序。（2）存储结构要求：可用顺序存储结构。也易于在链表上实现。（3）时间复杂度：对长度为n的文件，需进行趟二路归并，每趟归并的时间为O(n)，故其时间复杂度无论是在最好情况下还是在最坏情况下均是O(nlgn)。（4）空间复杂度：需要一个辅助向量来暂存两有序子文件归并的结果，故其辅助空间复杂度为O(n)，显然它不是就地排序。 注意：若用单链表做存储结构，很容易给出就地的归并排序 12345678910111213141516171819202122232425262728293031323334353637public static int[] sort(int[] a,int low,int high)&#123; int mid = (low+high)/2; if(low&lt;high)&#123; sort(a,low,mid); sort(a,mid+1,high); //左右归并 merge(a,low,mid,high); &#125; return a; &#125; public static void merge(int[] a, int low, int mid, int high) &#123; int[] temp = new int[high-low+1]; int i= low; int j = mid+1; int k=0; // 把较小的数先移到新数组中 while(i&lt;=mid &amp;&amp; j&lt;=high)&#123; if(a[i]&lt;a[j])&#123; temp[k++] = a[i++]; &#125;else&#123; temp[k++] = a[j++]; &#125; &#125; // 把左边剩余的数移入数组 while(i&lt;=mid)&#123; temp[k++] = a[i++]; &#125; // 把右边边剩余的数移入数组 while(j&lt;=high)&#123; temp[k++] = a[j++]; &#125; // 把新数组中的数覆盖nums数组 for(int x=0;x&lt;temp.length;x++)&#123; a[x+low] = temp[x]; &#125; &#125; 堆排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Arrays;public class HeapSort &#123; public static void main(String[] args) &#123; int[] a=&#123;49,38,65,97,76,13,27,49,78,34,12,64&#125;; int arrayLength=a.length; //循环建堆 for(int i=0;i&lt;arrayLength-1;i++)&#123; //建堆 buildMaxHeap(a,arrayLength-1-i); //交换堆顶和最后一个元素 swap(a,0,arrayLength-1-i); System.out.println(Arrays.toString(a)); &#125; &#125; //对data数组从0到lastIndex建大顶堆 public static void buildMaxHeap(int[] data, int lastIndex)&#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; //交换 private static void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125;&#125; 基数排序123456789101112131415161718192021222324252627282930import java.util.*;public class RadixSort &#123; // 各位装通法 public int[] radixSort(int[] A, int n) &#123; int length = n; int divisor = 1;// 定义每一轮的除数，1,10,100... //定义了10个桶，以防每一位都一样全部放入一个桶中 int[][] bucket = new int[10][length]; int[] count = new int[10];// 统计每个桶中实际存放的元素个数 int digit;// 获取元素中对应位上的数字，即装入那个桶 for (int i = 1; i &lt;= 3; i++) &#123;// 经过4次装通操作，排序完成 for (int temp : A) &#123;// 计算入桶 digit = (temp / divisor) % 10; bucket[digit][count[digit]++] = temp; &#125; int k = 0;// 被排序数组的下标 for (int b = 0; b &lt; 10; b++) &#123;// 从0到9号桶按照顺序取出 if (count[b] == 0)// 如果这个桶中没有元素放入，那么跳过 continue; for (int w = 0; w &lt; count[b]; w++) &#123; A[k++] = bucket[b][w]; &#125; count[b] = 0;// 桶中的元素已经全部取出，计数器归零 &#125; divisor *= 10; &#125; return A; &#125;&#125; 总结1.若n较小(如n≤50)，可采用直接插入或直接选择排序。 当记录规模较小时，直接插入排序较好；否则因为直接选择移动的记录数少于直接插人，应选直接选择排序为宜。2.若文件初始状态基本有序(指正序)，则应选用直接插人、冒泡或随机的快速排序为宜；3.若n较大，则应采用时间复杂度为O(nlgn)的排序方法：快速排序、堆排序或归并排序。4.快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；5.堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。6.若要求排序稳定，则可选用归并排序。","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/数据结构与算法/"}]},{"title":"HashMap的工作原理","date":"2018-04-03T10:28:28.000Z","path":"2018/04/03/HashMap的工作原理/","text":"“你用过HashMap吗？” “什么是HashMap？你为什么用到它？”几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题： “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法： “当两个对象的hashcode相同会发生什么？” 从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。 “如果两个键的hashcode相同，你如何获取值对象？”面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者知道HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 “如果HashMap的大小超过了负载因子(loadfactor)定义的容量，怎么办？”默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 散列表的hash算法是根据移位来进行计算的，只能是进行＊2或者／2。因此，扩容的大小要符合这个标准，否则会造成没必要的浪费甚至错误。扩容的成本并不低，因为需要遍历一个时间复杂度为O(n)的数组，并且为其中的每个enrty进行hash计算。加入到新数组中，所以最好的情况是能够合理的使用HashMap的构造方法创建合适大小的HashMap，使得在不浪费内存的情况下，尽量减少扩容，这个就要根据业务来决定了。 “你了解重新调整HashMap大小存在什么问题吗？”你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(racecondition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？ 热心的读者贡献了更多的关于HashMap的问题： 为什么String,Interger这样的wrapper类适合作为键？ String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。 我们可以使用自定义的对象作为键吗？ 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。 我们可以使用CocurrentHashMap来代替Hashtable吗？这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。 我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点： hashing的概念 HashMap中解决碰撞的方法 equals()和hashCode()的应用，以及它们在HashMap中的重要性 不可变对象的好处 HashMap多线程的条件竞争 重新调整HashMap的大小 总结1. 什么时候会使用HashMap？它有什么特点？ 是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2.HashMap的工作原理 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将Key传给get()方法，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。HashMap在每个链表节点中储存键值对对象。 3. 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？HashMap中解决碰撞的方法 通过对key的hashCode()进行hashing，并计算下标( n-1 &amp; hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题。 4. 你知道hash的实现吗？为什么要这样实现？在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。 5. 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法计算index，把节点再放到新的bucket中。 6.当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 转载自：http://www.importnew.com/10620.html","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"Hello,My Blog","date":"2018-04-02T13:17:30.000Z","path":"2018/04/02/Hello-My-Blog/","text":"纵有疾风起，人生不言弃 花了一天半的时间终于开通了自己的博客。参照网上教程从下载Node.js、Hexo到下载博客模板、调试、配置成自己想要的样子，以及学这个Markdown语法，中间也遇到了一些小小的Bug，有些百度出来了，有的自己解决了，有的还没解决就只能小小的掩盖一下，以后慢慢学习，不断进步，慢慢解决吧。 虽然是借用了Hexo的模板，并挂在Github上的免费博客，但还是希望自己以后能坚持写下去，能将学习过程中的点点滴滴都能记录下来！纵有疾风起，人生不言弃！","tags":[]},{"title":"Hello World","date":"2018-04-01T15:50:22.104Z","path":"2018/04/01/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]