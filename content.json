[{"title":"悲观锁与乐观锁","date":"2018-04-04T13:34:13.000Z","path":"2018/04/04/悲观锁与乐观锁/","text":"定义1.悲观锁：即很悲观，每次拿数据的时候都觉得数据会被人更改，所以拿数据的时候就把这条记录锁掉，这样别人就没法改这条数据了，一直到你的锁释放。 2.乐观锁：即很乐观，查询数据的时候总觉得不会有人更改数据，等到更新的时候再判断这个数据有没有被人更改，有人更改了则本次更新失败。 实现过程悲观锁：悲观锁的实现采用的数据库内部的锁机制，一个典型的倚赖数据库的悲观锁调用： 1select * from account where name=\"张三\" for update; 这条sql 语句锁定了account 表中所有符合检索条件（name=”张三”）的记录。本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。也就是我们可以在查询数据的时候先用for update把这条数据锁住，然后更改完这条数据再提交。这样别的线程没法更新这条数据，也就保证了不会丢失更新。 悲观锁带来的性能问题。我们试想一个场景：如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进行修改时（如更改用户帐户余额），如果采用悲观锁机制，也就意味着整个操作过程中（从操作员读出数据、开始修改直至提交修改结果的全过程），数据库记录始终处于加锁状态，可以想见，如果面对几百上千个并发，这样的情况将导致怎样的后果？所以我们这个时候可以使用乐观锁。 优点与不足 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数 乐观锁：乐观锁的实现可以通过在表里面加一个版本号的形式，每个人更新的时候都会判断当前的版本号是否跟我查询出来得到的版本号是否一致，不一致就更新失败，一致就更新这条记录并更改版本号。 优点与不足 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就遇到了问题。 使用场景像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。","tags":[{"name":"数据库","slug":"数据库","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/数据库/"}]},{"title":"synchronized与Lock的区别","date":"2018-04-04T13:07:54.000Z","path":"2018/04/04/synchronized与Lock的区别/","text":"类别 synchronized Lock 存在层次 Java的关键字，在jvm层面上 是一个类 锁的释放 1、已获取锁的线程执行完同步代码会释放锁 2、线程执行发生异常，jvm会让线程释放锁 需在finally中手工释放锁（unlock()方法释放锁），不然容易造成线程死锁 锁的获取 假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待 分情况而定，如果尝试获取不到锁，线程可以不用一直等待 锁状态 无法判断是否获取到锁 可以判断是否获取到锁 锁类型 可重入 不可中断 非公平 可重入 可判断 可公平（两者皆可） 性能 适合代码少量的同步问题 适合代码大量的同步问题 两种锁的底层实现方式： synchronized： 我们知道java是用字节码指令来控制程序（这里不包括热点代码编译成机器码）。在字节指令中，存在有synchronized所包含的代码块，那么会形成2段流程的执行。 其实synchronized映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当一条线程进行执行的遇到monitorenter指令的时候，它会去尝试获得锁，如果获得锁那么锁计数+1（为什么会加一呢，因为它是一个可重入锁，所以需要用这个锁计数判断锁的情况），如果没有获得锁，那么阻塞。当它遇到monitorexit的时候，锁计数器-1，当计数器为0，那么就释放锁。 那有两个monitorexit呀？synchronized锁释放有两种机制，一种就是执行完释放；另外一种就是发送异常，虚拟机释放。第二个monitorexit就是发生异常时执行的流程，这就是我开头说的“会有2个流程存在“。 Lock： Lock实现和synchronized不一样，后者是一种悲观锁，它胆子很小，它很怕有人和它抢吃的，所以它每次吃东西前都把自己关起来。而Lock底层其实是CAS乐观锁的体现，它无所谓，别人抢了它吃的，它重新去拿吃的就好啦，所以它很乐观。底层主要靠volatile和CAS操作实现的。 尽可能去使用synchronized而不要去使用LOCK 转载自：https://blog.csdn.net/u012403290/article/details/64910926?locationNum=11&amp;fps=1","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"List接口的实现类--ArrayList、LinkedList、Vector之间的区别","date":"2018-04-04T11:54:20.000Z","path":"2018/04/04/List接口的实现类-ArrayList、LinkedList、Vector之间的区别/","text":"概述Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└Set ArrayList是基于数组实现的，是一个动态数组，其容量能自动增长。 ArrayList不是线程安全的，只能用在单线程环境下。 允许元素为null 实现了Serializable接口，因此它支持序列化，能够通过序列化传输； 实现了RandomAccess接口，支持快速随机访问，可以以O(1)的时间复杂度去根据下标访问元素，实际上就是通过下标序号进行快速访问； 实现了Cloneable接口，能被克隆。 因其底层数据结构是数组，它占据了一块连续的内存空间（容量就是数组的length），所以它也有数组的缺点，空间效率不高。 由于数组的内存连续，可以根据下标以O(1)的时间读写(改查)元素，因此时间效率很高。 初始化 首先有三种方式来初始化： 1public ArrayList(); 默认的构造器，将会以默认的大小来初始化内部的数组 1public ArrayList(Collection&lt;? extends E&gt; c) 用一个ICollection对象来构造，并将该集合的元素添加到ArrayList 1public ArrayList(int initialCapacity) ArrayList的扩容机制使用无参构造方法时系统会默认提供默认参数10，而使用有参构造函数时我们会指定大小。在arraylist中增加一个对象的时候，Java会去检查arraylist，以确保已存在的数组中有足够的容量来存储这个新的对象。如果没有足够容量的话，那么就会新建一个长度更长的数组（通常为原数组的1.5倍）（当第一次插入元素时分配10个对象空间。假如有20个数据需要添加，那么会分别在第一次的时候，将ArrayList的容量变为10；之后扩容会按照1.5倍增长。也就是当添加第11个数据的时候，Arraylist继续扩容变为10 1.5=15，当添加第16个数据时，继续扩容变为15 1.5 =22个），旧的数组就会使用Arrays.copyOf方法被复制到新的数组中去，现有的数组指向了新的数组。 扩容操作也是ArrayList 的一个性能消耗比较大的地方，所以若我们可以提前预知数据的规模，应该通过public ArrayList(int initialCapacity) {}构造方法，指定集合的大小，去构建ArrayList实例，以减少扩容次数，提高效率。 或者在需要扩容的时候，手动调用public void ensureCapacity(intminCapacity) {}方法扩容。 不过该方法是ArrayList的API，不是List接口里的，所以使用时需要强转: ((ArrayList)list).ensureCapacity(30); ArrayList、LinkedList与List的不同（什么情况下你会使用ArrayList？什么时候你会选择LinkedList？）1.List是接口类，ArrayList和LinkedList是List的实现类。 2.ArrayList是动态数组（顺序表）的数据结构。顺序表的存储地址是连续的，所以在查找比较快，但是在插入和删除时，由于需要把其它的元素顺序向后移动（或向前移动），所以比较耗时。 3.LinkedList是链表的数据结构。链表的存储地址是不连续的，每个存储地址通过指针指向，在查找时需要进行通过指针遍历元素，所以在查找时比较慢。由于链表插入时不需移动其它元素，所以在插入和删除时比较快。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 在ArrayList中增加或者删除某个元素，通常会调用System.arraycopy方法，这是一种极为消耗资源的操作，因此，在频繁的插入或者是删除元素的情况下，LinkedList的性能会更加好一点。 ArrayList和LinkedList的时间复杂度ArrayList 是线性表（数组） get()：直接读取第几个下标，复杂度 O(1) add(E) ：添加元素，直接在后面添加，复杂度O（1） add(index, E) ：添加元素，在第几个元素后面插入，后面的元素需要向后移动，复杂度O（n） remove（）：删除元素，后面的元素需要逐个移动，复杂度O（n） LinkedList 是链表的操作 get()：获取第几个元素，依次遍历，复杂度O(n) add(E) ：添加到末尾，复杂度O(1) add(index, E) ：添加第几个元素后，需要先查找到第几个元素，直接指针指向操作，复杂度O(n) remove（）：删除元素，直接指针指向操作，复杂度O(1) 如何复制某个ArrayList到另一个ArrayList中去？1.使用clone()方法，比如ArrayList newArray = oldArray.clone(); 2.使用ArrayList构造方法，比如：ArrayList myObject = new ArrayList(myTempObject); 3.使用Collections的copy方法。 注意1和2是浅拷贝(shallowcopy)。 ArrayList为什么是线程不安全的？ArrayList在添加一个元素的时候，它可能会有两步来完成： 在 Items[Size] 的位置存放此元素； 增大 Size 的值。 在单线程运行的情况下，如果 Size = 0，添加一个元素后，此元素在位置 0，而且 Size=1；而如果是在多线程情况下，比如有两个线程，线程 A 先将元素存放在位置 0。但是此时 CPU 调度线程A暂停，线程 B 得到运行的机会。线程B也向此ArrayList 添加元素，因为此时 Size 仍然等于 0（注意哦，我们假设的是添加一个元素是要两个步骤哦，而线程A仅仅完成了步骤1），所以线程B也将元素存放在位置0。然后线程A和线程B都继续运行，都增加 Size 的值。那好，现在我们来看看 ArrayList 的情况，元素实际上只有一个，存放在位置 0，而 Size 却等于 2。这就是“线程不安全”了。 用Collections.synchronizedList可以把一个普通ArrayList包装成一个线程安全版本的数组容器，原理同Vector是一样的，就是给所有的方法套上一层synchronized。 ArrayList和Vector的区别？ArrayList和Vector都实现了list接口，都是数组实现； 区别在于Vector在API上都加了synchronized所以它是线程安全的，以及Vector扩容时，是扩容100%，而ArrayList是扩容50%。如果在集合中使用数据量比较大的数据，用vector有一定的优势。 stack Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"Java代码执行顺序","date":"2018-04-04T08:41:44.000Z","path":"2018/04/04/Java代码执行顺序/","text":"实例： 123456789101112131415161718192021222324252627282930313233343536373839class Person&#123; static &#123; System.out.println(\"执行Person静态代码块\"); &#125; &#123; System.out.println(\"执行Person构造代码块\"); &#125; public Person()&#123; System.out.println(\"执行Person无参构造方法\"); &#125; public Person(String name)&#123; System.out.println(\"执行Person构造方法\"+ name); &#125;&#125;class Student extends Person&#123; static &#123; System.out.println(\"执行Student静态代码块\"); &#125; &#123; System.out.println(\"执行Student构造代码块\"); &#125; public Student(String name)&#123; super(name); System.out.println(\"执行Student构造方法\" + name); &#125; public Student()&#123; super(); System.out.println(\"执行Student无参构造方法\"); &#125;&#125;public class ExtendsStaticConstruct &#123; public static void main(String args[])&#123; Student student1 = new Student(\"ABC\"); System.out.println(\"--------------------\"); Student student2 = new Student(); &#125;&#125; 执行结果： 1234567891011执行Person静态代码块执行Student静态代码块执行Person构造代码块执行Person构造方法ABC执行Student构造代码块执行Student构造方法ABC--------------------执行Person构造代码块执行Person无参构造方法执行Student构造代码块执行Student无参构造方法 说明：一般的类里面包含：1、静态代码块（静态区、静态变量等）2、构造代码块（{ }中间的内容）3、构造方法 其执行顺序也是1、2、3先后执行，这里需要注意的是：考虑继承特性。子类与父类的执行顺序是：1、先执行父类的静态代码块（父1）2、子类的静态代码块（子1）3、父类构造代码块（父2）4、父类构造方法（父3）5、子类构造代码块（子2）6、子类构造方法（子3） 当一个类从被JVM装载开始，各种代码的执行顺序大致如下： 被JVM装载-&gt;执行父类的相关代码-&gt;如果有静态初始化，先执行静态初始化，且只执行一次，以后即使有该类实例化，也不会再执行-&gt;如果有静态代码块，以与静态初始化一样的方式执行-&gt;如果有new语句带来的实例化，先为成员变量分配空间，并绑定参数列表，隐式或显式执行super()，即父类的构造方法-&gt;执行非静态代码块-&gt;执行本类的构造函数-&gt;执行其他代码。 这里的执行顺序同子类构造中有一个默认的父类构造super()无关，不是执行到隐藏的super()才开始初始化父类的，类的初始化是分层初始化，即先初始化父类，再初始化子类，初始化每个类的过程中，进行类的初始化工作，先进性成员变量的初始化，成员变量的初始化顺序是：默认初始化，即int为0这种－&gt;显示初始化，例如给int型显示初始化了值－&gt;构造方法初始化，所以是这里执行到了构造方法。 但是一定要注意，父类初始化选择的构造方法却和子类中super 选择的构造相关。 转载自：https://blog.csdn.net/wuhaiwei002/article/details/55226155","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"HashTable、HashMap和ConCurrentHashMap区别","date":"2018-04-04T08:19:04.000Z","path":"2018/04/04/HashTable、HashMap和ConCurrentHashMap区别/","text":"Map├Hashtable├HashMap└WeakHashMap HashMap和HashTable的对比 1.HashMap是非线程安全的，HashTable是线程安全的。 Hashtable中的线程安全是Synchronize的（sychronized意味着在一次仅有一个线程能够更改Hashtable，就是说任何线程要更新Hashtable时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新Hashtable）；而HashMap中的方法在缺省情况下是非Synchronize的。所以在单线程环境下Hashtable比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。 在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用HashMap时就必须要自己增加同步处理： Map m =Collections.synchronizedMap(new HashMap(…))。 2.HashMap的键和值都允许有null存在，而HashTable则都不行。 3.因为线程安全、哈希效率的问题，HashMap效率比HashTable的要高。 4.哈希值的使用不同 HashTable直接使用对象的hashCode。而HashMap重新计算hash值。 5.内部实现使用的数组初始化和扩容方式不同 HashMap默认初始化数组的大小为16，要求底层数组的容量一定要为2的整数次幂，HashTable为11。HashMap扩容时乘2，使用位运算取得哈希，效率高于取模。而HashTable为乘2加1，都是素数和奇数，这样取模哈希结果更均匀。 6.继承的父类不同 Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类。但二者都实现了Map接口。 7.两个遍历方式的内部实现上不同 Hashtable、HashMap都使用了 Iterator。而由于历史原因，Hashtable还使用了Enumeration的方式。 8.是否提供contains方法 HashMap把Hashtable的contains方法去掉了，改成containsValue和containsKey，因为contains方法容易让人引起误解。 Hashtable则保留了contains，containsValue和containsKey三个方法，其中contains和containsValue功能相同。 HashTable和ConCurrentHashMap的对比ConcurrentHashMap引入了分割(Segment)，把一个大的Map拆分成N个小的HashTable，在put方法中，会根据hash(paramK.hashCode())来决定具体存放进哪个Segment，如果查看Segment的put操作，我们会发现内部使用的同步机制是基于lock操作的，这样就可以对Map的一部分（Segment）进行上锁，这样影响的只是将要放入同一个Segment的元素的put操作，保证同步的时候，锁住的不是整个Map（HashTable就是这么做的），相对于HashTable提高了多线程环境下的性能，因此HashTable已经被淘汰了。 HashMap和ConCurrentHashMap的对比（1）ConcurrentHashMap对整个桶数组进行了分割分段(Segment)，然后在每一个分段上都用lock锁进行保护，相对于HashTable的syn关键字锁的粒度更精细了一些，并发性能更好，而HashMap没有锁机制，不是线程安全的。 （2）HashMap的键值对允许有null，但是ConCurrentHashMap都不允许。","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"排序算法","date":"2018-04-03T13:18:20.000Z","path":"2018/04/03/排序算法/","text":"综述内排序有可以分为以下几类： (1)、插入排序：直接插入排序、二分法插入排序、希尔排序。(2)、选择排序：简单选择排序、堆排序。(3)、交换排序：冒泡排序、快速排序。(4)、归并排序(5)、基数排序 排序方法 平均情况 最好情况 最坏情况 空间复杂度 稳定性 插入排序 O(n2) O(n) O(n2) O(1) 稳定 shell排序 O(n1.3) O(n) O(n2) O(1) 不稳定 选择排序 O(n2) O(n2) O(n2) O(1) 不稳定 堆排序 O(nlog2n) O(nlog2n) O(nlog2n) O(1) 不稳定 冒泡排序 O(n2) O(n) O(n2) O(1) 稳定 快速排序 O(nlog2n) O(nlog2n) O(n2) O(nlog2n) 不稳定 归并排序 O(nlog2n) O(nlog2n) O(nlog2n) O(1) 稳定 基数排序 O(d(r+n)) O(d(r+rd)) O(d(r+n)) O(rd+n) 稳定 注：基数排序 r表示关键字的基数 d代表长度 n代表关键字的个数 - O（n2）排序冒泡排序基本思想：比较数组相邻的两个值，把大的像泡泡一样“冒”到数组后面去，一共要执行N的平方除以2这么多次的比较和交换的操作（N为数组元素），其复杂度为Ο(n²)。 1234567891011public static void bubbleSort(int[] arr)&#123; for(int i=0;i&lt;arr.length-1;i++)&#123;//外层循环控制排序趟数 for(int j=0;j&lt;arr.length-1-i;j++)&#123;//内层循环控制每一趟排序多少次 if(arr[j]&gt;arr[j+1])&#123; int temp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=temp; &#125; &#125; &#125;&#125; 选择排序123456789101112131415161718public static void selectsort(int[] arr)&#123; if(arr == null || arr.length &lt; 2)&#123; return; &#125; for(int i=0;i&lt;arr.length;i++)&#123; int index = i;//初始下标为i for(int j=i+1;j&lt;arr.length;j++)&#123; if(arr[j]&lt;arr[index])&#123; index = j; &#125; &#125; if(index != i)&#123; int temp = arr[index]; arr[index] = arr[i]; arr[i] = temp; &#125; &#125;&#125; 插入排序基本思想：每步将一个待排序的记录，按其顺序码大小插入到前面已经排序的字序列的合适位置（从后向前找到合适位置后），直到全部插入排序完为止。 1234567891011public static void insertSort(int[] a) &#123; for(int i = 1; i &lt; a.length; i++) &#123;// 从数组的第二个元素开始循环将数组中的元素插入 int temp = a[i];// 设置数组中的第2个元素为第一次循环要插入的数据 int j = i - 1; while (j &gt;= 0 &amp;&amp; temp &lt; a[j]) &#123; a[j + 1] = a[j];// 如果要插入的元素小于第j个元素,就将第j个元素向后移动 j--; &#125; a[j + 1] = temp;// 直到要插入的元素不小于第j个元素,将temp插入到数组中 &#125;&#125; shell排序基本思想：本质是插入排序，通过将数组数组的方式来将增加排序的速度，分组的方式第一次将数组的长度/2,第二次/4,当结果等于1的时候，那么将这个数组进行插入排序就完成了排序，当然分组时也是需要排序的。 123456789101112131415public static void shellSort(int[] a) &#123; // 将数组分组 for (int temp = a.length / 2; temp &gt;= 1; temp /= 2) &#123; // 这里的思路和插入排序的思路相同，通过找到前一个的数大于或者小于来进行插入 for(int i = temp; i &lt; a.length; i += temp) &#123; int temp = a[i]; int j = i - temp; while(j &gt;= 0 &amp;&amp; temp &lt; a[j]) &#123; a[j + temp] = a[j]; j -= temp; &#125; a[j + temp] = temp; &#125; &#125; &#125; O（nlog2n）排序快速排序12345678910111213141516171819public static void quickSort(int[] arr,int low,int high)&#123; if(low &gt; high)&#123; return ; &#125; int i = low, j = high,temp = arr[low]; while(i &lt; j)&#123; while( arr[j] &gt;= temp &amp;&amp; i &lt; j)&#123; j--; &#125; arr[i] = arr[j]; while(arr[i] &lt;= temp &amp;&amp; i &lt; j)&#123; i++; &#125; arr[j] = arr[i]; &#125; arr[j] = temp; quickSort(arr,low,j-1); quickSort(arr,j+1,high);&#125; 归并排序（1）稳定性：归并排序是一种稳定的排序。（2）存储结构要求：可用顺序存储结构。也易于在链表上实现。（3）时间复杂度：对长度为n的文件，需进行趟二路归并，每趟归并的时间为O(n)，故其时间复杂度无论是在最好情况下还是在最坏情况下均是O(nlgn)。（4）空间复杂度：需要一个辅助向量来暂存两有序子文件归并的结果，故其辅助空间复杂度为O(n)，显然它不是就地排序。 注意：若用单链表做存储结构，很容易给出就地的归并排序 12345678910111213141516171819202122232425262728293031323334353637public static int[] sort(int[] a,int low,int high)&#123; int mid = (low+high)/2; if(low&lt;high)&#123; sort(a,low,mid); sort(a,mid+1,high); //左右归并 merge(a,low,mid,high); &#125; return a; &#125; public static void merge(int[] a, int low, int mid, int high) &#123; int[] temp = new int[high-low+1]; int i= low; int j = mid+1; int k=0; // 把较小的数先移到新数组中 while(i&lt;=mid &amp;&amp; j&lt;=high)&#123; if(a[i]&lt;a[j])&#123; temp[k++] = a[i++]; &#125;else&#123; temp[k++] = a[j++]; &#125; &#125; // 把左边剩余的数移入数组 while(i&lt;=mid)&#123; temp[k++] = a[i++]; &#125; // 把右边边剩余的数移入数组 while(j&lt;=high)&#123; temp[k++] = a[j++]; &#125; // 把新数组中的数覆盖nums数组 for(int x=0;x&lt;temp.length;x++)&#123; a[x+low] = temp[x]; &#125; &#125; 堆排序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Arrays;public class HeapSort &#123; public static void main(String[] args) &#123; int[] a=&#123;49,38,65,97,76,13,27,49,78,34,12,64&#125;; int arrayLength=a.length; //循环建堆 for(int i=0;i&lt;arrayLength-1;i++)&#123; //建堆 buildMaxHeap(a,arrayLength-1-i); //交换堆顶和最后一个元素 swap(a,0,arrayLength-1-i); System.out.println(Arrays.toString(a)); &#125; &#125; //对data数组从0到lastIndex建大顶堆 public static void buildMaxHeap(int[] data, int lastIndex)&#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; //交换 private static void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125;&#125; 基数排序123456789101112131415161718192021222324252627282930import java.util.*;public class RadixSort &#123; // 各位装通法 public int[] radixSort(int[] A, int n) &#123; int length = n; int divisor = 1;// 定义每一轮的除数，1,10,100... //定义了10个桶，以防每一位都一样全部放入一个桶中 int[][] bucket = new int[10][length]; int[] count = new int[10];// 统计每个桶中实际存放的元素个数 int digit;// 获取元素中对应位上的数字，即装入那个桶 for (int i = 1; i &lt;= 3; i++) &#123;// 经过4次装通操作，排序完成 for (int temp : A) &#123;// 计算入桶 digit = (temp / divisor) % 10; bucket[digit][count[digit]++] = temp; &#125; int k = 0;// 被排序数组的下标 for (int b = 0; b &lt; 10; b++) &#123;// 从0到9号桶按照顺序取出 if (count[b] == 0)// 如果这个桶中没有元素放入，那么跳过 continue; for (int w = 0; w &lt; count[b]; w++) &#123; A[k++] = bucket[b][w]; &#125; count[b] = 0;// 桶中的元素已经全部取出，计数器归零 &#125; divisor *= 10; &#125; return A; &#125;&#125; 总结1.若n较小(如n≤50)，可采用直接插入或直接选择排序。 当记录规模较小时，直接插入排序较好；否则因为直接选择移动的记录数少于直接插人，应选直接选择排序为宜。2.若文件初始状态基本有序(指正序)，则应选用直接插人、冒泡或随机的快速排序为宜；3.若n较大，则应采用时间复杂度为O(nlgn)的排序方法：快速排序、堆排序或归并排序。4.快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；5.堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。6.若要求排序稳定，则可选用归并排序。","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/数据结构与算法/"}]},{"title":"HashMap的工作原理","date":"2018-04-03T10:28:28.000Z","path":"2018/04/03/HashMap的工作原理/","text":"“你用过HashMap吗？” “什么是HashMap？你为什么用到它？”几乎每个人都会回答“是的”，然后回答HashMap的一些特性，譬如HashMap可以接受null键值和值，而Hashtable则不能；HashMap是非synchronized;HashMap很快；以及HashMap储存的是键值对等等。这显示出你已经用过HashMap，而且对它相当的熟悉。但是面试官来个急转直下，从此刻开始问出一些刁钻的问题，关于HashMap的更多基础的细节。面试官可能会问出下面的问题： “你知道HashMap的工作原理吗？” “你知道HashMap的get()方法的工作原理吗？”但一些面试者可能可以给出答案，“HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry。这一点有助于理解获取对象的逻辑。如果你没有意识到这一点，或者错误的认为仅仅只在bucket中存储值的话，你将不会回答如何从HashMap中获取对象的逻辑。这个答案相当的正确，也显示出面试者确实知道hashing以及HashMap的工作原理。但是这仅仅是故事的开始，当面试官加入一些Java程序员每天要碰到的实际场景的时候，错误的答案频现。下个问题可能是关于HashMap中的碰撞探测(collision detection)以及碰撞的解决方法： “当两个对象的hashcode相同会发生什么？” 从这里开始，真正的困惑开始了，一些面试者会回答因为hashcode相同，所以两个对象是相等的，HashMap将会抛出异常，或者不会存储它们。然后面试官可能会提醒他们有equals()和hashCode()两个方法，并告诉他们两个对象就算hashcode相同，但是它们可能并不相等。一些面试者可能就此放弃，而另外一些还能继续挺进，他们回答“因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。”这个答案非常的合理，虽然有很多种处理碰撞的方法，这种方法是最简单的，也正是HashMap的处理方法。 “如果两个键的hashcode相同，你如何获取值对象？”面试者会回答：当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象。面试官提醒他如果有两个值对象储存在同一个bucket，他给出答案:将会遍历链表直到找到值对象。面试官会问因为你并没有值对象去比较，你是如何确定确定找到值对象的？除非面试者知道HashMap在链表中存储的是键值对，否则他们不可能回答出这一题。 其中一些记得这个重要知识点的面试者会说，找到bucket位置之后，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。完美的答案！ 许多情况下，面试者会在这个环节中出错，因为他们混淆了hashCode()和equals()方法。因为在此之前hashCode()屡屡出现，而equals()方法仅仅在获取值对象的时候才出现。一些优秀的开发者会指出使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 “如果HashMap的大小超过了负载因子(loadfactor)定义的容量，怎么办？”默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。 散列表的hash算法是根据移位来进行计算的，只能是进行＊2或者／2。因此，扩容的大小要符合这个标准，否则会造成没必要的浪费甚至错误。扩容的成本并不低，因为需要遍历一个时间复杂度为O(n)的数组，并且为其中的每个enrty进行hash计算。加入到新数组中，所以最好的情况是能够合理的使用HashMap的构造方法创建合适大小的HashMap，使得在不浪费内存的情况下，尽量减少扩容，这个就要根据业务来决定了。 “你了解重新调整HashMap大小存在什么问题吗？”你可能回答不上来，这时面试官会提醒你当多线程的情况下，可能产生条件竞争(racecondition)。 当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。这个时候，你可以质问面试官，为什么这么奇怪，要在多线程的环境下使用HashMap呢？ 热心的读者贡献了更多的关于HashMap的问题： 为什么String,Interger这样的wrapper类适合作为键？ String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。 我们可以使用自定义的对象作为键吗？ 这是前一个问题的延伸。当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。 我们可以使用CocurrentHashMap来代替Hashtable吗？这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。 我个人很喜欢这个问题，因为这个问题的深度和广度，也不直接的涉及到不同的概念。让我们再来看看这些问题设计哪些知识点： hashing的概念 HashMap中解决碰撞的方法 equals()和hashCode()的应用，以及它们在HashMap中的重要性 不可变对象的好处 HashMap多线程的条件竞争 重新调整HashMap的大小 总结1. 什么时候会使用HashMap？它有什么特点？ 是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2.HashMap的工作原理 HashMap基于hashing原理，我们通过put()和get()方法储存和获取对象。当我们将键值对传递给put()方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到bucket位置来储存值对象，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将Key传给get()方法，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对，然后返回值对象。HashMap使用链表来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。HashMap在每个链表节点中储存键值对对象。 3. 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？HashMap中解决碰撞的方法 通过对key的hashCode()进行hashing，并计算下标( n-1 &amp; hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题。 4. 你知道hash的实现吗？为什么要这样实现？在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。 5. 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法计算index，把节点再放到新的bucket中。 6.当两个不同的键对象的hashcode相同时会发生什么？ 它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。 转载自：http://www.importnew.com/10620.html","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://bameirilyo.github.io/BameirilyoBlog/tags/Java基础/"}]},{"title":"Hello,My Blog","date":"2018-04-02T13:17:30.000Z","path":"2018/04/02/Hello-My-Blog/","text":"纵有疾风起，人生不言弃 花了一天半的时间终于开通了自己的博客。参照网上教程从下载Node.js、Hexo到下载博客模板、调试、配置成自己想要的样子，以及学这个Markdown语法，中间也遇到了一些小小的Bug，有些百度出来了，有的自己解决了，有的还没解决就只能小小的掩盖一下，以后慢慢学习，不断进步，慢慢解决吧。 虽然是借用了Hexo的模板，并挂在Github上的免费博客，但还是希望自己以后能坚持写下去，能将学习过程中的点点滴滴都能记录下来！纵有疾风起，人生不言弃！","tags":[]},{"title":"Hello World","date":"2018-04-01T15:50:22.104Z","path":"2018/04/01/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]